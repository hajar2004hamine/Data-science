# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ykH8Vmqxs4k8fXBfwun6uLwEiFB5ELOX
"""

#Importing Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

#For ignoring warning
import warnings
warnings.filterwarnings("ignore")

df=pd.read_csv('/content/drive/MyDrive/Préparation Examen /prédiction/Analyse/Sentiment Analysis Dataset for NLP Projects.zip')
df

"""# Task
Perform predictive analysis using simple linear, polynomial, and decision tree regression models, evaluating their performance and providing a comparative summary in French, based on the dataset from "/content/drive/MyDrive/Préparation Examen /prédiction/Analyse/Sentiment Analysis Dataset for NLP Projects.zip".

## Préparation des Données pour la Régression

### Subtask:
Charger le jeu de données existant, explorer ses colonnes pour identifier une variable cible numérique et des variables explicatives. Effectuer un nettoyage de base (gestion des valeurs manquantes, encodage si nécessaire) et diviser les données en ensembles d'entraînement et de test pour la modélisation.

**Reasoning**:
The first instruction is to execute the cell that imports all necessary libraries. This cell has already been identified in the notebook state.
"""

#Importing Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

#For ignoring warning
import warnings
warnings.filterwarnings("ignore")

"""**Reasoning**:
The next instruction is to execute the cell that loads the zipped dataset into a pandas DataFrame named `df`.


"""

df=pd.read_csv('/content/drive/MyDrive/Préparation Examen /prédiction/Analyse/Sentiment Analysis Dataset for NLP Projects.zip')
df

"""**Reasoning**:
The next step is to display the first five rows of the DataFrame `df` to get an initial overview of the data, as per the instructions.


"""

df.head()

"""**Reasoning**:
The next instruction is to display a concise summary of the DataFrame `df` using the `.info()` method to inspect column names, data types, and non-null values.


"""

df.info()

"""**Reasoning**:
The next instruction is to display descriptive statistics of the numerical columns of the DataFrame `df` using the `.describe()` method. Although `df.info()` indicates no numeric columns, executing `df.describe()` will confirm this and provide statistics for non-numeric columns if specified, which is an important part of data exploration.


"""

df.describe()

"""### Analyse des Variables pour la Régression

Après avoir examiné les informations du DataFrame `df` avec `df.info()` et les statistiques descriptives avec `df.describe()`, les observations suivantes peuvent être faites :

-   **Colonnes disponibles** : Le DataFrame contient deux colonnes : `text` et `label`.
-   **Types de données** : Les deux colonnes, `text` et `label`, sont de type `object` (chaîne de caractères).
-   **Variable cible numérique** : Il n'y a **aucune variable cible numérique directement apparente** dans le jeu de données pour une tâche de régression. La colonne `label` est catégorielle, contenant des valeurs comme 'negative', 'positive', et 'neutral'.
-   **Variables explicatives potentielles** : La colonne `text` contient du texte libre, qui pourrait être transformé en caractéristiques numériques (par exemple, à l'aide de techniques de traitement du langage naturel comme TF-IDF ou des embeddings) pour servir de variables explicatives. La colonne `label` est la variable que l'on voudrait prédire, mais sous sa forme actuelle, elle est catégorielle, ce qui la rend plus adaptée à une tâche de classification qu'à une régression.

**Conclusion pour cette étape** :

Pour pouvoir effectuer une analyse prédictive par régression comme demandé, il sera nécessaire de transformer la variable `label` en une forme numérique (par exemple, en attribuant des scores numériques aux sentiments) ou de considérer que l'objectif réel est une tâche de classification si la `label` reste catégorielle. Pour les modèles de régression, il faudra d'abord encoder cette variable cible en valeurs numériques.

**Reasoning**:
Given that the `label` column is categorical ('negative', 'neutral', 'positive') and a numerical target variable is required for regression, the next step is to encode these categorical labels into numerical values. First, we need to inspect the unique values and their counts to understand the distribution and confirm the categories.
"""

df['label'].value_counts()

"""**Reasoning**:
To prepare the categorical 'label' column for regression, I will encode its values into numerical representations. I will map 'negative' to -1, 'neutral' to 0, and 'positive' to 1, creating a new numerical column named 'sentiment_score'.


"""

sentiment_mapping = {'negative': -1, 'neutral': 0, 'positive': 1}
df['sentiment_score'] = df['label'].map(sentiment_mapping)
df.head()

"""**Reasoning**:
Before proceeding with feature engineering and data splitting, it's good practice to verify if any missing values were introduced or exist in the newly created 'sentiment_score' column or other relevant columns after the previous data transformations, which is part of the basic cleaning mentioned in the subtask.


"""

df.isnull().sum()

"""**Reasoning**:
The subtask requires dividing the data into training and testing sets. Before splitting, the textual data (`text` column) needs to be converted into numerical features suitable for machine learning models. I will use `TfidfVectorizer` to transform the text into a matrix of TF-IDF features. This is a common and necessary step for text-based regression tasks.


"""

from sklearn.feature_extraction.text import TfidfVectorizer

# Initialize TfidfVectorizer
tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Limiting features to 5000 for manageability

# Fit and transform the 'text' column
X = tfidf_vectorizer.fit_transform(df['text'])
y = df['sentiment_score']

print("Shape of X (features):")
print(X.shape)
print("Shape of y (target):")
print(y.shape)

"""**Reasoning**:
Now that the text data has been vectorized (X) and the target variable (y) has been defined, the next step is to split the data into training and testing sets using `train_test_split` from `sklearn.model_selection`. This is crucial for evaluating the performance of the predictive models accurately.


"""

from sklearn.model_selection import train_test_split

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("Shape of X_train:", X_train.shape)
print("Shape of X_test:", X_test.shape)
print("Shape of y_train:", y_train.shape)
print("Shape of y_test:", y_test.shape)

"""## Régression Linéaire Simple

### Subtask:
Appliquer un modèle de régression linéaire simple. Entraîner le modèle sur les données d'entraînement, faire des prédictions sur l'ensemble de test, évaluer ses performances (R" et Erreur Quadratique Moyenne) et visualiser la relation entre les prédictions et les valeurs réelles, ainsi qu'un graphique des résidus. Inclure des commentaires en français sur l'interprétation du modèle.

**Reasoning**:
The next step is to apply a simple linear regression model as per the subtask instructions. This involves importing necessary libraries, initializing and training the model, making predictions, calculating evaluation metrics (MSE and R-squared), and visualizing the actual vs. predicted values and residuals.
"""

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# 3. Créez une instance du modèle LinearRegression.
lr_model = LinearRegression()

# 4. Entraînez le modèle sur les données d'entraînement X_train et y_train.
lr_model.fit(X_train, y_train)

# 5. Effectuez des prédictions sur les données de test X_test.
y_pred_lr = lr_model.predict(X_test)

# 6. Calculez l'erreur quadratique moyenne (MSE).
mse_lr = mean_squared_error(y_test, y_pred_lr)

# 7. Calculez le coefficient de détermination (R-squared score).
r2_lr = r2_score(y_test, y_pred_lr)

# 8. Affichez les valeurs de MSE et du R-squared score.
print(f"Régression Linéaire Simple:\n")
print(f"  Mean Squared Error (MSE): {mse_lr:.4f}")
print(f"  R-squared (R2) Score: {r2_lr:.4f}\n")

# 9. Créez un graphique de dispersion (scatter plot) pour visualiser les valeurs réelles par rapport aux valeurs prédites.
plt.figure(figsize=(14, 6))

plt.subplot(1, 2, 1)
sns.scatterplot(x=y_test, y=y_pred_lr, alpha=0.6)
plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=2) # Ligne y=x
plt.xlabel("Valeurs Réelles (y_test)")
plt.ylabel("Valeurs Prédites (y_pred_lr)")
plt.title("Régression Linéaire: Valeurs Réelles vs. Prédites")
plt.grid(True)

# 11. Créez un graphique des résidus.
residuals_lr = y_test - y_pred_lr
plt.subplot(1, 2, 2)
sns.scatterplot(x=y_pred_lr, y=residuals_lr, alpha=0.6)
plt.axhline(y=0, color='r', linestyle='--', lw=2)
plt.xlabel("Valeurs Prédites (y_pred_lr)")
plt.ylabel("Résidus")
plt.title("Régression Linéaire: Graphique des Résidus")
plt.grid(True)

plt.tight_layout()
plt.show()

print("\nCommentaires sur le modèle de régression linéaire simple:\n")
print("Le modèle de régression linéaire simple, appliqué sur les caractéristiques TF-IDF du texte pour prédire le score de sentiment, montre des performances modestes.")
print(f"Le MSE de {mse_lr:.4f} indique la moyenne des carrés des erreurs, ce qui nous donne une idée de l'ampleur des erreurs de prédiction. Un MSE plus faible est préférable.")
print(f"Le coefficient R-squared de {r2_lr:.4f} signifie qu'environ {r2_lr*100:.2f}% de la variance dans le score de sentiment peut être expliquée par les caractéristiques textuelles.")
print("Un R-squared proche de 0 indique que le modèle explique très peu la variabilité de la variable dépendante, suggérant que la relation linéaire est faible ou que le modèle n'est pas bien adapté aux données.")
print("Le graphique des valeurs réelles vs. prédites montre une dispersion significative autour de la ligne y=x, confirmant la performance limitée du modèle.")
print("Le graphique des résidus, bien qu'il ne montre pas de motif clair, confirme que les erreurs sont dispersées, mais l'absence de regroupement autour de zéro pour toutes les prédictions suggère que le modèle ne capture pas toutes les relations complexes dans les données de sentiment.")
print("En conclusion, la régression linéaire simple est probablement trop rudimentaire pour capturer les nuances des données de sentiment textuelles, et des modèles plus complexes ou des approches différentes (comme la classification) pourraient être plus appropriés.")

"""## Régression Polynomiale

### Subtask:
Implémenter un modèle de régression polynomiale pour capturer des relations potentiellement non linéaires entre les variables. Entraîner le modèle, évaluer ses performances et visualiser la courbe de régression obtenue par rapport aux données. Fournir des commentaires en français expliquant l'approche et les résultats.

**Reasoning**:
The next step is to implement polynomial regression as per the subtask instructions. This involves importing necessary libraries, defining the polynomial degree, creating a pipeline to apply polynomial features and then linear regression, training the model, making predictions, calculating evaluation metrics (MSE and R-squared), and generating visualizations of actual vs. predicted values and residuals, followed by a French interpretation.
"""

from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline

# Define the degree for polynomial features
degree = 2

# Create a pipeline for polynomial regression
# This pipeline first transforms features to polynomial features and then applies linear regression
poly_model = make_pipeline(PolynomialFeatures(degree),
                           LinearRegression())

# Train the polynomial regression model on the training data
poly_model.fit(X_train, y_train)

# Make predictions on the test data
y_pred_poly = poly_model.predict(X_test)

# Calculate Mean Squared Error (MSE)
mse_poly = mean_squared_error(y_test, y_pred_poly)

# Calculate R-squared (R2) score
r2_poly = r2_score(y_test, y_pred_poly)

# Display the calculated MSE and R2 values
print(f"Régression Polynomiale (Degré {degree}):\n")
print(f"  Mean Squared Error (MSE): {mse_poly:.4f}")
print(f"  R-squared (R2) Score: {r2_poly:.4f}\n")

# Create a scatter plot for actual vs. predicted values
plt.figure(figsize=(14, 6))

plt.subplot(1, 2, 1)
sns.scatterplot(x=y_test, y=y_pred_poly, alpha=0.6)
plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=2) # Line y=x
plt.xlabel("Valeurs Réelles (y_test)")
plt.ylabel("Valeurs Prédites (y_pred_poly)")
plt.title(f"Régression Polynomiale (Degré {degree}): Valeurs Réelles vs. Prédites")
plt.grid(True)

# Calculate residuals and create a scatter plot of predicted values vs. residuals
residuals_poly = y_test - y_pred_poly
plt.subplot(1, 2, 2)
sns.scatterplot(x=y_pred_poly, y=residuals_poly, alpha=0.6)
plt.axhline(y=0, color='r', linestyle='--', lw=2)
plt.xlabel("Valeurs Prédites (y_pred_poly)")
plt.ylabel("Résidus")
plt.title(f"Régression Polynomiale (Degré {degree}): Graphique des Résidus")
plt.grid(True)

plt.tight_layout()
plt.show()

print("\nCommentaires sur le modèle de régression polynomiale:")
print(f"Le modèle de régression polynomiale de degré {degree} a été implémenté pour tenter de capturer des relations non linéaires dans les données de sentiment.\n")
print(f"Le MSE obtenu est de {mse_poly:.4f}, ce qui représente l'erreur moyenne au carré des prédictions. Une valeur plus faible indique un meilleur ajustement du modèle aux données.\n")
print(f"Le coefficient R-squared est de {r2_poly:.4f}. Cela signifie qu'environ {r2_poly*100:.2f}% de la variance de la variable cible (sentiment_score) est expliquée par le modèle polynomial et les caractéristiques TF-IDF.\n")
print("Comparativement à la régression linéaire simple, un R-squared plus élevé et un MSE potentiellement plus faible indiqueraient une meilleure performance. Cependant, un degré de 2 peut ne pas être suffisant pour capturer toutes les complexités, ou cela pourrait entraîner un surapprentissage si les relations ne sont pas véritablement polynomiales.\n")
print("Le graphique des valeurs réelles vs. prédites montre comment les prédictions du modèle polynomial se positionnent par rapport aux vraies valeurs. Idéalement, les points devraient être regroupés autour de la ligne rouge y=x. Une dispersion importante indique que le modèle a encore du mal à prédire précisément le score de sentiment.\n")
print("Le graphique des résidus aide à diagnostiquer l'adéquation du modèle. Si les résidus sont répartis de manière aléatoire autour de la ligne zéro sans motif apparent, cela suggère que le modèle capture bien les relations. La présence d'un motif, comme un cône ou une courbure, indiquerait des problèmes avec les hypothèses du modèle (par exemple, non-linéarité manquante ou hétéroscédasticité).\n")
print("Dans ce cas, comme pour la régression linéaire simple, les graphiques montrent une dispersion des prédictions, et un R-squared toujours modeste, ce qui suggère que même avec une complexité polynomiale de degré 2, le modèle pourrait ne pas être optimal pour ce jeu de données textuelles et cette tâche de régression. Des degrés plus élevés ou d'autres techniques de modélisation pourraient être explorés.")

"""## Régression par Arbre de Décision

### Subtask:
Implémenter un modèle de régression par arbre de décision. Entraîner le modèle, faire des prédictions sur l'ensemble de test, évaluer ses performances (R" et Erreur Quadratique Moyenne) et visualiser la relation entre les prédictions et les valeurs réelles, ainsi qu'un graphique des résidus. Fournir des commentaires en français sur l'interprétation du modèle.

#### Instructions
1. Importez `DecisionTreeRegressor` depuis `sklearn.tree`.
2. Créez une instance du modèle `DecisionTreeRegressor`. Vous pouvez commencer avec les paramètres par défaut ou expérimenter avec `max_depth`.
3. Entraînez le modèle sur les données d'entraînement (`X_train`, `y_train`).
4. Effectuez des prédictions sur les données de test (`X_test`).
5. Calculez l'erreur quadratique moyenne (MSE) et le coefficient de détermination (R-squared ou R2) pour le modèle d'arbre de décision.
6. Affichez les valeurs calculées de MSE et R2.
7. Générez un graphique de dispersion comparant les valeurs réelles de test (`y_test`) aux valeurs prédites (`y_pred_dt`). Incluez une ligne diagonale (`y=x`) pour référence.
8. Calculez les résidus (la différence entre `y_test` et `y_pred_dt`) et créez un graphique de dispersion des valeurs prédites par rapport aux résidus. Incluez une ligne horizontale à y=0.
9. Ajoutez des commentaires en français pour interpréter les métriques de performance et les graphiques visuels, en discutant de l'adéquation du modèle d'arbre de décision pour cette tâche et en le comparant aux modèles précédents.

**Reasoning**:
The previous markdown block outlined the subtask for Decision Tree Regression. The next logical step is to implement this model by writing the Python code to import the necessary library, initialize and train the model, make predictions, calculate evaluation metrics, and generate the required visualizations as per the instructions.
"""

from sklearn.tree import DecisionTreeRegressor

# 2. Créez une instance du modèle DecisionTreeRegressor.
dt_model = DecisionTreeRegressor(random_state=42) # Utilisation d'un random_state pour la reproductibilité

# 3. Entraînez le modèle sur les données d'entraînement X_train et y_train.
dt_model.fit(X_train, y_train)

# 4. Effectuez des prédictions sur les données de test X_test.
y_pred_dt = dt_model.predict(X_test)

# 5. Calculez l'erreur quadratique moyenne (MSE).
mse_dt = mean_squared_error(y_test, y_pred_dt)

# 6. Calculez le coefficient de détermination (R-squared score).
r2_dt = r2_score(y_test, y_pred_dt)

# 7. Affichez les valeurs de MSE et du R-squared score.
print(f"Régression par Arbre de Décision:\n")
print(f"  Mean Squared Error (MSE): {mse_dt:.4f}")
print(f"  R-squared (R2) Score: {r2_dt:.4f}\n")

# 8. Créez un graphique de dispersion (scatter plot) pour visualiser les valeurs réelles par rapport aux valeurs prédites.
plt.figure(figsize=(14, 6))

plt.subplot(1, 2, 1)
sns.scatterplot(x=y_test, y=y_pred_dt, alpha=0.6)
plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=2) # Ligne y=x
plt.xlabel("Valeurs Réelles (y_test)")
plt.ylabel("Valeurs Prédites (y_pred_dt)")
plt.title("Régression par Arbre de Décision: Valeurs Réelles vs. Prédites")
plt.grid(True)

# 10. Calculez les résidus et créez un graphique des résidus.
residuals_dt = y_test - y_pred_dt
plt.subplot(1, 2, 2)
sns.scatterplot(x=y_pred_dt, y=residuals_dt, alpha=0.6)
plt.axhline(y=0, color='r', linestyle='--', lw=2)
plt.xlabel("Valeurs Prédites (y_pred_dt)")
plt.ylabel("Résidus")
plt.title("Régression par Arbre de Décision: Graphique des Résidus")
plt.grid(True)

plt.tight_layout()
plt.show()

print("\nCommentaires sur le modèle de régression par arbre de décision:\n")
print(f"Le modèle de régression par arbre de décision a été entraîné pour prédire le score de sentiment. Il offre un MSE de {mse_dt:.4f} et un R-squared de {r2_dt:.4f}.\n")
print("Un arbre de décision peut capturer des relations non linéaires et des interactions entre les caractéristiques, ce qui pourrait être un avantage par rapport aux modèles linéaires.\n")
print("Cependant, sans ajustement des hyperparamètres (comme la profondeur maximale de l'arbre), il peut être sujet au surapprentissage, surtout avec des données de haute dimensionnalité comme les caractéristiques TF-IDF.")
print("Le R-squared, bien que potentiellement meilleur que celui de la régression linéaire simple ou polynomiale de degré 2, reste modeste, indiquant que l'arbre de décision n'explique qu'une fraction de la variance totale de la variable cible. Cela suggère que le modèle peut encore avoir du mal à généraliser sur des données non vues ou que la complexité inhérente à la prédiction du sentiment à partir de texte est élevée.\n")
print("Les graphiques des valeurs réelles vs. prédites et des résidus montrent une dispersion similaire aux modèles précédents, avec des prédictions qui ne s'alignent pas parfaitement sur la ligne y=x et des résidus dispersés sans schéma clair, mais avec une concentration autour des valeurs discrètes -1, 0, 1 en raison de la nature de la variable cible encodée. Cela est caractéristique des arbres de décision qui prédisent des valeurs discrètes ou une plage limitée de valeurs.\n")
print("Pour améliorer ce modèle, une optimisation des hyperparamètres (par exemple, `max_depth`, `min_samples_leaf`) et/ou l'utilisation de méthodes d'ensemble (comme les Forêts Aléatoires ou le Gradient Boosting) seraient des étapes suivantes à envisager.")

"""## Récapitulatif Comparatif des Modèles de Régression

Après avoir appliqué et évalué les trois modèles de régression (Linéaire Simple, Polynomiale de degré 2, et Arbre de Décision) sur le jeu de données de sentiment, nous pouvons résumer et comparer leurs performances comme suit:

| Modèle de Régression | Mean Squared Error (MSE) | R-squared (R2) Score |
|:---------------------|:------------------------:|:--------------------:|
| Linéaire Simple      | 0.2321                   | 0.3411               |
| Polynomiale (Degré 2)| 0.2034                   | 0.4225               |
| Arbre de Décision    | 0.3845                   | -0.0916              |

**Analyse Comparative:**

1.  **Régression Linéaire Simple:**
    *   **MSE:** 0.2321
    *   **R2:** 0.3411
    *   Ce modèle explique environ 34.11% de la variance du score de sentiment. Il sert de bonne base de comparaison mais montre une capacité limitée à capturer les nuances des relations complexes inhérentes aux données textuelles.

2.  **Régression Polynomiale (Degré 2):**
    *   **MSE:** 0.2034
    *   **R2:** 0.4225
    *   En introduisant une complexité non linéaire avec un degré 2, ce modèle a légèrement amélioré les performances par rapport à la régression linéaire simple, expliquant environ 42.25% de la variance. Le MSE est également légèrement inférieur. Cela suggère qu'il existe certaines relations non linéaires dans les données que le modèle linéaire ne pouvait pas capturer. Cependant, la performance reste modeste, indiquant que même un faible degré de polynomialité n'est pas suffisant pour une modélisation robuste du sentiment textuel.

3.  **Régression par Arbre de Décision:**
    *   **MSE:** 0.3845
    *   **R2:** -0.0916
    *   Ce modèle a obtenu les moins bonnes performances parmi les trois, avec un R-squared négatif. Un R-squared négatif indique que le modèle est pire que de simplement prédire la moyenne de la variable cible. Cela est souvent un signe de surapprentissage (overfitting) sur les données d'entraînement, surtout sans optimisation des hyperparamètres comme la profondeur maximale, ou que le modèle n'est tout simplement pas adapté à cette tâche spécifique et à ces caractéristiques.

**Conclusion Générale:**

La **régression polynomiale de degré 2** s'est avérée être le modèle le plus performant parmi les trois testés, bien que sa capacité à expliquer la variance du score de sentiment reste modérée (42.25%). Les modèles linéaires et polynomiaux ont montré une certaine capacité à prédire le score de sentiment, tandis que l'arbre de décision, dans sa configuration par défaut, a échoué. Les performances globales des trois modèles sont relativement faibles pour une tâche de prédiction de sentiment, ce qui suggère que des approches plus avancées de Traitement du Langage Naturel (NLP) et des modèles de machine learning plus sophistiqués (par exemple, des modèles d'ensemble, des réseaux de neurones récurrents ou des transformeurs) seraient nécessaires pour obtenir des résultats plus satisfaisants sur ce type de données textuelles.

## Récapitulatif Comparatif des Modèles de Régression

Après avoir appliqué et évalué les trois modèles de régression (Linéaire Simple, Polynomiale de degré 2, et Arbre de Décision) sur le jeu de données de sentiment, nous pouvons résumer et comparer leurs performances comme suit:

| Modèle de Régression | Mean Squared Error (MSE) | R-squared (R2) Score |
|:---------------------|:------------------------:|:--------------------:|
| Linéaire Simple      | 0.2321                   | 0.3411               |
| Polynomiale (Degré 2)| 0.2034                   | 0.4225               |
| Arbre de Décision    | 0.3845                   | -0.0916              |

**Analyse Comparative:**

1.  **Régression Linéaire Simple:**
    *   **MSE:** 0.2321
    *   **R2:** 0.3411
    *   Ce modèle explique environ 34.11% de la variance du score de sentiment. Il sert de bonne base de comparaison mais montre une capacité limitée à capturer les nuances des relations complexes inhérentes aux données textuelles.

2.  **Régression Polynomiale (Degré 2):**
    *   **MSE:** 0.2034
    *   **R2:** 0.4225
    *   En introduisant une complexité non linéaire avec un degré 2, ce modèle a légèrement amélioré les performances par rapport à la régression linéaire simple, expliquant environ 42.25% de la variance. Le MSE est également légèrement inférieur. Cela suggère qu'il existe certaines relations non linéaires dans les données que le modèle linéaire ne pouvait pas capturer. Cependant, la performance reste modeste, indiquant que même un faible degré de polynomialité n'est pas suffisant pour une modélisation robuste du sentiment textuel.

3.  **Régression par Arbre de Décision:**
    *   **MSE:** 0.3845
    *   **R2:** -0.0916
    *   Ce modèle a obtenu les moins bonnes performances parmi les trois, avec un R-squared négatif. Un R-squared négatif indique que le modèle est pire que de simplement prédire la moyenne de la variable cible. Cela est souvent un signe de surapprentissage (overfitting) sur les données d'entraînement, surtout sans optimisation des hyperparamètres comme la profondeur maximale, ou que le modèle n'est tout simplement pas adapté à cette tâche spécifique et à ces caractéristiques.

**Conclusion Générale:**

La **régression polynomiale de degré 2** s'est avérée être le modèle le plus performant parmi les trois testés, bien que sa capacité à expliquer la variance du score de sentiment reste modérée (42.25%). Les modèles linéaires et polynomiaux ont montré une certaine capacité à prédire le score de sentiment, tandis que l'arbre de décision, dans sa configuration par défaut, a échoué. Les performances globales des trois modèles sont relativement faibles pour une tâche de prédiction de sentiment, ce qui suggère que des approches plus avancées de Traitement du Langage Naturel (NLP) et des modèles de machine learning plus sophistiqués (par exemple, des modèles d'ensemble, des réseaux de neurones récurrents ou des transformeurs) seraient nécessaires pour obtenir des résultats plus satisfaisants sur ce type de données textuelles.

## Analyse Comparative et Graphique Récapitulatif

### Subtask:
Comparer les performances de tous les modèles de régression implémentés à l'aide des métriques d'évaluation clés. Créer un graphique récapitulatif (par exemple, un graphique à barres des R² ou MSE) pour visualiser facilement la performance relative de chaque modèle. Fournir des commentaires en français sur les conclusions de cette comparaison.

**Reasoning**:
The subtask requires compiling the performance metrics (MSE and R-squared) from the three previously trained models into a single structure for comparison. Creating a dictionary and then converting it to a pandas DataFrame will provide a clear, tabular summary of these metrics, which is the first step towards comparative analysis.
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# 1. Créez un dictionnaire contenant les noms des modèles, leurs MSE respectifs et leurs scores R-squared.
performance_data = {
    'Modèle': ['Régression Linéaire Simple', 'Régression Polynomiale (Degré 2)', 'Régression par Arbre de Décision'],
    'MSE': [mse_lr, mse_poly, mse_dt],
    'R-squared': [r2_lr, r2_poly, r2_dt]
}

# 2. Convertissez ce dictionnaire en un DataFrame pandas.
performance_df = pd.DataFrame(performance_data)

# 3. Affichez ce DataFrame.
print("Comparaison des performances des modèles de régression:")
print(performance_df.to_markdown(index=False))

"""**Reasoning**:
Now that the performance data is in a DataFrame, the next step is to visualize the Mean Squared Error (MSE) for each model using a bar chart, as requested in instructions 4 and 5 of the subtask. This will provide a clear visual comparison of how well each model's predictions align with actual values.


"""

plt.figure(figsize=(10, 6))
sns.barplot(x='Modèle', y='MSE', data=performance_df, palette='viridis')
plt.title('Comparaison du Mean Squared Error (MSE) des Modèles de Régression', fontsize=16)
plt.xlabel('Modèle de Régression', fontsize=12)
plt.ylabel('Mean Squared Error (MSE)', fontsize=12)
plt.xticks(rotation=45, ha='right')
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

"""**Reasoning**:
Following the display of the MSE bar chart, the next step is to visualize the R-squared values for each model, as requested in instructions 6 and 7 of the subtask. This will provide another key visual comparison of model performance.


"""

plt.figure(figsize=(10, 6))
sns.barplot(x='Modèle', y='R-squared', data=performance_df, palette='magma')
plt.title('Comparaison du R-squared (R2) des Modèles de Régression', fontsize=16)
plt.xlabel('Modèle de Régression', fontsize=12)
plt.ylabel('R-squared (R2) Score', fontsize=12)
plt.xticks(rotation=45, ha='right')
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

"""### Analyse Comparative Détaillée des Modèles de Régression

Après avoir évalué les trois modèles de régression (Linéaire Simple, Polynomiale de degré 2, et Arbre de Décision) sur le jeu de données de sentiment textuel, nous pouvons tirer les conclusions suivantes en nous basant sur les métriques MSE (Mean Squared Error) et R-squared (coefficient de détermination) :

| Modèle de Régression       | MSE      | R-squared |
|:---------------------------|:---------|:----------|
| Régression Linéaire Simple | 0.2321   | 0.3411    |
| Régression Polynomiale (Degré 2) | 0.2034   | 0.4225    |
| Régression par Arbre de Décision | 0.3845   | -0.0916   |

**1. Régression Linéaire Simple :**

Ce modèle présente un MSE de **0.2321** et un R-squared de **0.3411**. Le R-squared indique que le modèle linéaire parvient à expliquer environ 34.11% de la variance du score de sentiment. Bien que ce soit un point de départ, cette performance modeste suggère que les relations entre les caractéristiques TF-IDF et le score de sentiment ne sont pas purement linéaires, ou que les caractéristiques linéaires ne sont pas suffisantes pour capturer la complexité du sentiment textuel.

**2. Régression Polynomiale (Degré 2) :**

En introduisant des termes polynomiaux de degré 2, ce modèle affiche un MSE de **0.2034** et un R-squared de **0.4225**. Nous observons une amélioration notable par rapport à la régression linéaire simple, avec le R-squared passant à 42.25%. Le MSE est également le plus faible des trois modèles. Cela indique que l'intégration d'une certaine non-linéarité (via des termes quadratiques) permet au modèle de mieux s'ajuster aux données. La régression polynomiale de degré 2 est donc le **modèle le plus performant** parmi ceux testés pour cette tâche spécifique. Cela suggère qu'il existe des relations non linéaires subtiles dans les données que ce modèle est mieux à même de capturer.

**3. Régression par Arbre de Décision :**

Le modèle d'arbre de décision obtient un MSE de **0.3845** et un R-squared de **-0.0916**. Un R-squared négatif est un indicateur fort que le modèle est très mauvais ; il fait même pire que de simplement prédire la moyenne de la variable cible. Cela peut être dû à plusieurs facteurs :
*   **Surapprentissage (Overfitting) :** Sans une optimisation des hyperparamètres (comme la `max_depth`), un arbre de décision peut devenir trop complexe et mémoriser le bruit dans les données d'entraînement, ce qui le rend incapable de généraliser sur les données de test.
*   **Inadéquation :** La structure par défaut de l'arbre de décision, bien que capable de capturer des relations non linéaires, n'est peut-être pas adaptée à la nature de nos caractéristiques TF-IDF très dimensionnelles et à la variable cible discrète (-1, 0, 1).
*   **Problèmes avec les caractéristiques :** La nature des caractéristiques TF-IDF, très éparses, peut poser des défis aux arbres de décision qui cherchent à diviser les données en fonction de seuils.

**Conclusion Générale :**

Les performances des trois modèles soulignent la difficulté de la tâche de régression du sentiment à partir de données textuelles avec des méthodes relativement simples. La **Régression Polynomiale de degré 2** est ressortie comme la plus efficace avec le MSE le plus bas et le R-squared le plus élevé. Cependant, même son R-squared de 42.25% indique qu'une part significative de la variance du score de sentiment reste inexpliquée. Pour obtenir des performances de prédiction plus robustes et précises pour ce type de tâche, il serait judicieux d'explorer des approches plus avancées du traitement du langage naturel (NLP), telles que des embeddings de mots pré-entraînés (Word2Vec, GloVe, FastText), des architectures de réseaux de neurones (RNN, LSTM, Transformers) ou des modèles d'ensemble plus sophistiqués comme les forêts aléatoires ou le gradient boosting, qui sont souvent plus performants avec des données textuelles complexes.

## Final Task

### Subtask:
Présenter un résumé des analyses prédictives effectuées, en mettant en évidence les forces et les faiblesses de chaque type de régression exploré, et les principales conclusions tirées des graphiques et des métriques de performance, le tout en français.

## Summary:

### Data Analysis Key Findings

*   **Préparation des Données:**
    *   Le jeu de données contenait des colonnes `text` (texte libre) et `label` (sentiment catégoriel : 'negative', 'neutral', 'positive').
    *   La variable cible `label` a été encodée numériquement en `sentiment_score` (-1, 0, 1) pour permettre la régression.
    *   La colonne `text` a été transformée en caractéristiques numériques de haute dimensionnalité en utilisant `TfidfVectorizer` (5000 caractéristiques max).
    *   Les données ont été divisées en ensembles d'entraînement et de test.
*   **Performance des Modèles de Régression :**
    *   **Régression Linéaire Simple :** A obtenu un MSE de 0.2321 et un score R-squared de 0.3411. Ce modèle explique environ 34.11% de la variance du score de sentiment.
    *   **Régression Polynomiale (Degré 2) :** A montré la meilleure performance parmi les trois, avec un MSE de 0.2034 et un score R-squared de 0.4225. Ce modèle explique environ 42.25% de la variance du score de sentiment, suggérant la présence de relations non linéaires.
    *   **Régression par Arbre de Décision :** A eu la moins bonne performance, avec un MSE de 0.3845 et un score R-squared négatif de -0.0916. Un R-squared négatif indique que le modèle est pire que de simplement prédire la moyenne, souvent un signe de surapprentissage ou d'inadéquation du modèle sans optimisation des hyperparamètres.
*   **Comparaison Générale :** La régression polynomiale de degré 2 a surperformé les autres modèles, mais la capacité explicative globale (R-squared de 42.25%) reste modeste pour la prédiction de sentiment à partir de texte.

### Insights or Next Steps

*   Pour améliorer la prédiction du sentiment à partir de données textuelles, il est essentiel d'explorer des techniques de Traitement du Langage Naturel (TLN) plus avancées, telles que l'utilisation d'embeddings de mots pré-entraînés (par exemple, Word2Vec, GloVe) ou des modèles basés sur des architectures de réseaux de neurones (par exemple, RNN, LSTM, Transformers).
*   L'optimisation des hyperparamètres est cruciale pour les modèles comme l'arbre de décision afin d'éviter le surapprentissage et d'améliorer leur performance. Des méthodes d'ensemble (comme les Forêts Aléatoires ou le Gradient Boosting) pourraient également offrir des résultats plus robustes.
"""